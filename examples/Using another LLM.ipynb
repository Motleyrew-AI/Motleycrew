{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84dd9af7-ba68-429e-b9b2-eb2ab8ee54fc",
   "metadata": {},
   "source": [
    "# Using another LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860c41f2-d1aa-4cc9-a92e-bec59043c5db",
   "metadata": {},
   "source": [
    "At present, we default to using OpenAI models, and rely on the user to set the `OPENAI_API_KEY` environment variable.\n",
    "\n",
    "You can control the default LLM as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe153839-f056-4159-98d4-4f366184e78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from motleycrew.common import Defaults\n",
    "Defaults.DEFAULT_LLM_FAMILY = the_new_default_LLM_family\n",
    "Defaults.DEFAULT_LLM_NAME = name_of_the_new_default_model_within_the_family"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e7dad1-490e-4912-9b05-d2cbad00d1f1",
   "metadata": {},
   "source": [
    "For this to work, you must make sure that for all the frameworks you're using (currently at most Langchain, LlamaIndex), the `LLM_MAP` has an entry for the new default LLM family, for example as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fc3846-d14c-424a-a61a-f956dff2dbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Defaults.LLM_MAP[ (LLMFramework.LANGCHAIN, \"MyLLMFamily\") ] = my_langchain_llm_factory\n",
    "Defaults.LLM_MAP[ (LLMFramework.LLAMA_INDEX, \"MyLLMFamily\") ] = my_llamaindex_llm_factory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e97371-5f3f-42f1-a321-363d62d42080",
   "metadata": {},
   "source": [
    "Here each llm factory is a function with a signature  ```def llm_factory(llm_name: str, llm_temperature: float, **kwargs)``` that returns the model object for the relevant framework. \n",
    "\n",
    "For example, this is the built-in OpenAI model factory for Langchain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ea0a52-a4c9-4c14-b744-1078ff48012b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def langchain_openai_llm(\n",
    "    llm_name: str = Defaults.DEFAULT_LLM_NAME,\n",
    "    llm_temperature: float = Defaults.DEFAULT_LLM_TEMPERATURE,\n",
    "    **kwargs,\n",
    "):\n",
    "    from langchain_openai import ChatOpenAI\n",
    "\n",
    "    return ChatOpenAI(model=llm_name, temperature=llm_temperature, **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f61ad1-96d0-410d-9349-48addaf85aa9",
   "metadata": {},
   "source": [
    "and here is the one for OpenAI and LlamaIndex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17067877-d99c-483c-a23b-a738790ea45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llama_index_openai_llm(\n",
    "    llm_name: str = Defaults.DEFAULT_LLM_NAME,\n",
    "    llm_temperature: float = Defaults.DEFAULT_LLM_TEMPERATURE,\n",
    "    **kwargs,\n",
    "):\n",
    "    ensure_module_is_installed(\"llama_index\")\n",
    "    from llama_index.llms.openai import OpenAI\n",
    "\n",
    "    return OpenAI(model=llm_name, temperature=llm_temperature, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b36baf8-5491-49fa-8ea3-0c33501af932",
   "metadata": {},
   "source": [
    "You can also overwrite the `LLM_MAP` values for e.g. the OpenAI models if, for example, you want to use an in-house wrapper for Langchain or Llamaindex model adapters (for example, to use an internal gateway instead of directly hitting the OpenAI endpoints) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9884f013-63f0-44a5-936b-6bc81909b94e",
   "metadata": {},
   "source": [
    "Note that at present, if you use Autogen with motleycrew, you will need to separately control the models that Autogen uses, using the Autogen-specific APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9883c816-4f22-4ee9-87db-53ab7a802571",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
